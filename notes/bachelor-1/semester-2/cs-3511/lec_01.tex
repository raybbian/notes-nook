\lecture{1}{Tue 09 Jan 2024 12:28}{Intro and Review}

\section{Intro to Algorithms}
\subsection{Properties of Algorithms}

What kind of properties can an algorithm even have?

\begin{property}
	Algorithms can be categorized by speed, memory, readability (simple to understand), accuracy (approximation quality), and requirements for the input.
\end{property}

The focus of this class will be on \textbf{speed}. We will also talk about accuracy, and algorithms will be mostly readable (but not always). We need some language that will allow us to describe algorithms.

\subsection{Describing Algorithms}

\begin{eg}
	Let's take for example selection sort.
\end{eg}
\begin{explanation}
	Using plain english, selection sort is: reapeatedly finding the smallest element and appending it to the output.
\end{explanation}

Algorithms can be described at different levels of detail. One extreme is very informally, like the sentence above. This type helps convey the \textbf{key concepts}, but can be rather vague, ambiguous, and hard to understand.

The other extreme could be posting the source code of the program. This would be a complete description of an algorithm, because even the computer and execute it. However, source code includes details that \textbf{only the computer needs}, such as types, etc.

So, when talking about algorithms, it makes sense to use a middleground, known as \textbf{pseudocode}.

\begin{definition}
	\textbf{Pseudocode} is a descriptive, step by step set of instructions that detail the structure of a program. English is allowed, and the level of detail depends on the context and the audience.
\end{definition}

\begin{algorithm}
	\floatname{algorithm}{Selection Sort}
	\algrenewcommand\algorithmicrequire{\textbf{Any array of elements}}
	\algrenewcommand\algorithmicensure{\textbf{A sorted array}}
	\caption{Pseudocode for Selection Sort}\label{alg:selection-sort}
	\begin{algorithmic}[1]
		\Require $input$
		\Ensure $output$
		\For{\( i \gets 1\ldots n \)}
			\State{Find \( j\ge i \) with smallest \( arr[j] \)}
			\State{Swap \( arr[i] \) and \( arr[j] \)}
		\EndFor
	\end{algorithmic}
\end{algorithm}

More detailed descriptions can also be given with pseudocode.

\subsection{Runtime of Algorithms}

Many factors can impact the runtime of an algorithm. For example, Selection Sort, when ran on the professor's laptop had a runtime of \( 0.017 n^2 + 0.669 n + 0.114\)ms. This runtime will vary depending on the context, things like hardware, the programming language, and temperature.

Because we cannot determine these constants for every computer, we will just \textbf{ignore them} for analyzing algorithms.

\begin{definition}
	\textbf{Big-O Notation} is the notation used to analyze runtimes. It essentially ignores unknown constant factors. More formally, it states that \( f(n)=O(g(n)) \) if and only if there exists \( n_0 \) and \( c>0 \) such that \( f(n) \le c\cdot g(n) ~ \forall n \ge n_0\).
\end{definition}

\begin{lemma}
	\( \lim_{n \to \infty} \frac{f(n)}{g(n)} < \infty \implies f(n) = O(g(n)) \).
\end{lemma}

We can find the runtime of algorithms by counting the number of operations.

\begin{eg}
	Selection sort runs in \( O(n^2) \).
\end{eg}
\begin{explanation}
	We have \[
		\sum_{i=1}^{n} \sum_{j=i}^{n} 1 =  \frac{n(n-1)}{2} = O(n^2)
	.\] 
	Note that the second equality comes from taking the limit.
\end{explanation}

\begin{definition}
	\textbf{Omega} notation denotes the relation \( \ge  \).
\end{definition}

\begin{lemma}
	\( \lim_{n \to \infty} \frac{g(n)}{f(n)} \implies f(n) = \Omega(g(n)) \).
\end{lemma}

\begin{definition}
	\textbf{Little-O} notation denotes the strict relation \( < \).
\end{definition}

\begin{lemma}
	\( \lim_{n \to \infty} \frac{f(n)}{g(n)}=0 \implies f(n) = o(g(n)) \).
\end{lemma}

\begin{definition}
	\textbf{Little Omega} notation denotes the strict relation \( > \).
\end{definition}

\begin{lemma}
	\( \lim_{n \to \infty} \frac{g(n)}{f(n)} \implies f(n) = \omega(g(n))\).
\end{lemma}

\begin{definition}
	\textbf{Theta} notation denotes the equality relation \( = \).
\end{definition}

\begin{lemma}
	\( f(n) = O(g(n)) \land f(n) = \Omega(g(n)) \implies f(n) = \Theta(g(n)) \).
\end{lemma}
