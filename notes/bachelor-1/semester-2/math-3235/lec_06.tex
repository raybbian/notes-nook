\lecture{6}{Thu 25 Jan 2024 14:02}{Multivariate Probability}

\section{Multivariate Probability}

Our objective is to treat random vectors \( (X,Y_{0} \in \mathbb{R}^{2} ) \) together as \[
	(X,Y) : \Omega ^{2} \to \mathbb{R}^{2} 
.\] 

\begin{definition}
	If \( X \) and \( Y \) are discrete random variables on \( (\Omega , \mathcal{F}, \mathbb{P}) \), the \textbf{joint probability mass function} \( P_{X,Y}(x,y) \) of \( X \) and \( Y \) is the function \[
		p_{X,Y} : \mathbb{R}^{2} \to [0, 1]
	.\] defined by 
	\begin{align*}
		&p_{X,Y}(x, y) \\ &= \mathbb{P}(\{\omega  \in \Omega : X(\omega ) = x \text{ and } Y(\omega )=y\}  )
	.\end{align*}
	and abbreviated \[
		p_{X,Y}(x, y) = \mathbb{P}(X=x, Y=y)
	.\] 
\end{definition}

\begin{note}
	The sum of all options still remains one.
\end{note}

\begin{eg}
	Two cards are drawn at random from a dech of 52 cards. If \( X \) denotes the number of aces drawn and \( Y \) denotes the number of kings, display the join mass function of \( X \), and \( Y \) in tabular form.
\end{eg}
\begin{explanation}
	Note that \( X = \{0,1,2\}, Y=\{0,1,2\}     \). Then, we have 
	\begin{center}
		\begin{tabular}{ |c| c c c| }
			\hline
			& \( X=0 \) & \( X=1 \) & \( X=2 \) \\
			\hline
			\( Y=0 \) & \( \frac{44}{52}\cdot \frac{43}{51} \) & \( \frac{\binom{4}{1} \cdot \binom{44}{1}}{\binom{52}{2}} \) & \( \frac{\binom{4}{2}}{\binom{52}{2}} \)\\ 
			\( Y=1 \) & \( \frac{\binom{4}{1} \cdot \binom{44}{1}}{\binom{52}{2}} \) & \( \frac{\binom{4}{1}\cdot \binom{4}{1}}{\binom{52}{2}} \) & 0 \\  
			\( Y=2 \) & \( \frac{\binom{4}{2}}{\binom{52}{2}} \) & 0 & 0 \\
			\hline
		\end{tabular}
	\end{center}
\end{explanation}

Note that we can expand this past 2 dimensions.

\begin{definition}
	Suppose that each of \( n \) experiments can result in any one of \( r \) possible outcomes, with proabilities, \( p_{1}, p_{2}, \ldots p_r \) which sum up to one. If we let \( X_I \) denote the nubmer of the \( n \) experiments that result in outcome number \( i \), then the probability mass function is given by 
	\begin{align*}
		&\mathbb{P}(X_{1}=n_{1},\ldots ,X_r=n_r) \\ &= \binom{n}{n_{1},n_{2},\ldots ,n_r} p_{1}^{n_{1}}  \cdot p_{2}^{n_{2}}  \cdot \ldots \cdot p_r^{n_r} 
	.\end{align*}
\end{definition}

\begin{definition}
	We have that
	\begin{align*}
		&\mathbb{E}(g(X,Y)) \\ &= \sum_{x \in \text{Im}X} \sum_{y \in \text{Im}Y} g(x,y)\mathbb{P}(X=x,Y=y)
	.\end{align*}
	when this sum converges absolutely.
\end{definition}

\begin{corollary}
	\[
		\mathbb{E}(aX + bY) = a\mathbb{E}(X) + b\mathbb{E}(Y)
	.\] 
\end{corollary}
